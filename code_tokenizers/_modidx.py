# Autogenerated by nbdev

d = { 'settings': { 'branch': 'main',
                'doc_baseurl': '/code_tokenizers',
                'doc_host': 'https://ncoop57.github.io',
                'git_url': 'https://github.com/ncoop57/code_tokenizers',
                'lib_path': 'code_tokenizers'},
  'syms': { 'code_tokenizers.cli': {'code_tokenizers.cli.download_grammars': ('cli.html#download_grammars', 'code_tokenizers/cli.py')},
            'code_tokenizers.core': { 'code_tokenizers.core.CodeTokenizer': ('core.html#codetokenizer', 'code_tokenizers/core.py'),
                                      'code_tokenizers.core.CodeTokenizer.__call__': ( 'core.html#codetokenizer.__call__',
                                                                                       'code_tokenizers/core.py'),
                                      'code_tokenizers.core.CodeTokenizer.__eq__': ( 'core.html#codetokenizer.__eq__',
                                                                                     'code_tokenizers/core.py'),
                                      'code_tokenizers.core.CodeTokenizer.__init__': ( 'core.html#codetokenizer.__init__',
                                                                                       'code_tokenizers/core.py'),
                                      'code_tokenizers.core.CodeTokenizer.__reduce__': ( 'core.html#codetokenizer.__reduce__',
                                                                                         'code_tokenizers/core.py'),
                                      'code_tokenizers.core.CodeTokenizer.decode': ( 'core.html#codetokenizer.decode',
                                                                                     'code_tokenizers/core.py'),
                                      'code_tokenizers.core.CodeTokenizer.from_pretrained': ( 'core.html#codetokenizer.from_pretrained',
                                                                                              'code_tokenizers/core.py'),
                                      'code_tokenizers.core.CodeTokenizer.parse_tree': ( 'core.html#codetokenizer.parse_tree',
                                                                                         'code_tokenizers/core.py'),
                                      'code_tokenizers.core.get_token_type': ('core.html#get_token_type', 'code_tokenizers/core.py'),
                                      'code_tokenizers.core.traverse': ('core.html#traverse', 'code_tokenizers/core.py'),
                                      'code_tokenizers.core.unroll_node_types': ('core.html#unroll_node_types', 'code_tokenizers/core.py')},
            'code_tokenizers.grammars.tree-sitter-python.examples.compound-statement-without-trailing-newline': {},
            'code_tokenizers.grammars.tree-sitter-python.examples.crlf-line-endings': {},
            'code_tokenizers.grammars.tree-sitter-python.examples.mixed-spaces-tabs': {},
            'code_tokenizers.grammars.tree-sitter-python.examples.multiple-newlines': {},
            'code_tokenizers.grammars.tree-sitter-python.examples.python2-grammar': {},
            'code_tokenizers.grammars.tree-sitter-python.examples.python2-grammar-crlf': {},
            'code_tokenizers.grammars.tree-sitter-python.examples.python3-grammar': {},
            'code_tokenizers.grammars.tree-sitter-python.examples.python3-grammar-crlf': {},
            'code_tokenizers.grammars.tree-sitter-python.examples.python3.8_grammar': {},
            'code_tokenizers.grammars.tree-sitter-python.examples.simple-statements-without-trailing-newline': {},
            'code_tokenizers.grammars.tree-sitter-python.examples.tabs': {},
            'code_tokenizers.grammars.tree-sitter-python.examples.trailing-whitespace': {},
            'code_tokenizers.grammars.tree-sitter-python.test.highlight.keywords': {},
            'code_tokenizers.grammars.tree-sitter-python.test.highlight.parameters': {},
            'code_tokenizers.grammars.tree-sitter-python.test.highlight.pattern_matching': {}}}

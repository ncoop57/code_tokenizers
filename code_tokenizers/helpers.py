# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_helpers.ipynb.

# %% auto 0
__all__ = ['CACHE_DIR', 'download_grammar', 'unroll_node_types', 'get_parser', 'get_query', 'get_internal_methods']

# %% ../nbs/02_helpers.ipynb 2
import json
import os
import shutil
import urllib
import zipfile


from pathlib import Path
from tree_sitter import Language, Parser

# %% ../nbs/02_helpers.ipynb 4
CACHE_DIR = Path.home() / ".cache" / "code_tokenizers"
CACHE_DIR.mkdir(parents=True, exist_ok=True)

# | export
_GRAMMARs = {
    "python": "https://github.com/tree-sitter/tree-sitter-python/archive/refs/tags/v0.20.0.zip",
}

# %% ../nbs/02_helpers.ipynb 5
def download_grammar(language):
    """
    Download the tree-sitter grammars for the specified languages.

    If the languages argument is the string 'all', all available grammars will be downloaded.
    Otherwise, the argument should be a list of language codes to download.
    """
    try:
        url = _GRAMMARs[language]
    except KeyError as e:
        raise ValueError(
            f"Invalid or unsupported language: {e}. Supported languages: {list(_GRAMMARs.keys())}"
        )

    langs = []
    grammar_dir = CACHE_DIR / "grammars"
    grammar_dir.mkdir(exist_ok=True)
    repo_dir = grammar_dir / language
    if not repo_dir.exists():
        # Download the tagged archive
        urllib.request.urlretrieve(url, f"{repo_dir}.zip")
        # Unzip the repository archive and remove the zip file
        with zipfile.ZipFile(f"{repo_dir}.zip", "r") as zip_ref:
            zip_ref.extractall(grammar_dir)
        os.remove(f"{repo_dir}.zip")
        # move the contents of the tagged archive to the repo directory
        for f in grammar_dir.iterdir():
            if f.is_dir() and f.name.startswith("tree-sitter-"):
                shutil.move(f, repo_dir)

    lang_file = repo_dir / "languages.so"
    if not lang_file.exists():
        Language.build_library(
            # Store the library in the directory
            str(lang_file),
            # Include one or more languages
            [repo_dir],
        )
    return lang_file

# %% ../nbs/02_helpers.ipynb 7
def unroll_node_types(
    nested_node_types: dict,  # node_types from tree-sitter
) -> list:  # list of node types
    """Unroll nested node types into a flat list of node types. This includes subtypes as well."""
    node_types = [node_type["type"] for node_type in nested_node_types]
    node_subtypes = [
        node_subtype["type"]
        for node_type in node_types
        if "subtypes" in node_type
        for node_subtype in node_type["subtypes"]
    ]
    return list(set(node_types + node_subtypes))

# %% ../nbs/02_helpers.ipynb 8
def get_parser(lang):
    lang_file = download_grammar(lang)
    language = Language(
        str(lang_file),
        lang,
    )
    # Grab the node types from the tree-sitter language
    node_path = lang_file.parent / "src" / "node-types.json"
    with open(node_path) as f:
        node_types = json.load(f)
    node_types = unroll_node_types(node_types)
    if lang == "python":
        node_types.append("as_pattern_target")
        node_types.append("ERROR")

    # Create a parser for the language
    parser = Parser()
    parser.set_language(language)
    return parser, node_types

# %% ../nbs/02_helpers.ipynb 10
def get_query(language, program_lang):
    "Get a query based on the language"
    if program_lang == "python":
        return language.query(
            """
            (function_definition
                name: (identifier) @func.name)

            (class_definition
                name: (identifier) @class.name)
            """
        )

# %% ../nbs/02_helpers.ipynb 11
def get_internal_methods(file_contents, tokenizer):
    """
    Get all the internal methods in a set of files
    """
    project_content = "\n\n".join(file_contents)
    tree = tokenizer.parser.parse(project_content.encode())
    root_node = tree.root_node
    query = get_query(tokenizer.language, tokenizer.program_lang)
    captures = query.captures(root_node)
    # make sure to ignore dunders
    internal_methods = {
        node.text.decode()
        for node, _ in captures
        if not node.text.decode().startswith("__")
    }
    return internal_methods

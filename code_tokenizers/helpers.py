# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/02_helpers.ipynb.

# %% auto 0
__all__ = ['BUILTINs', 'CACHE_DIR', 'download_grammar', 'unroll_node_types', 'get_parser', 'get_query', 'get_internal_methods']

# %% ../nbs/02_helpers.ipynb 2
import json
import os
import shutil
import urllib
import zipfile


from pathlib import Path
from tree_sitter import Language, Parser

# %% ../nbs/02_helpers.ipynb 4
BUILTINs = [
    "ArithmeticError",
    "AssertionError",
    "AttributeError",
    "BaseException",
    "BlockingIOError",
    "BrokenPipeError",
    "BufferError",
    "BytesWarning",
    "ChildProcessError",
    "ConnectionAbortedError",
    "ConnectionError",
    "ConnectionRefusedError",
    "ConnectionResetError",
    "DeprecationWarning",
    "EOFError",
    "Ellipsis",
    "EncodingWarning",
    "EnvironmentError",
    "Exception",
    "False",
    "FileExistsError",
    "FileNotFoundError",
    "FloatingPointError",
    "FutureWarning",
    "GeneratorExit",
    "IOError",
    "ImportError",
    "ImportWarning",
    "IndentationError",
    "IndexError",
    "InterruptedError",
    "IsADirectoryError",
    "KeyError",
    "KeyboardInterrupt",
    "LookupError",
    "MemoryError",
    "ModuleNotFoundError",
    "NameError",
    "None",
    "NotADirectoryError",
    "NotImplemented",
    "NotImplementedError",
    "OSError",
    "OverflowError",
    "PendingDeprecationWarning",
    "PermissionError",
    "ProcessLookupError",
    "RecursionError",
    "ReferenceError",
    "ResourceWarning",
    "RuntimeError",
    "RuntimeWarning",
    "StopAsyncIteration",
    "StopIteration",
    "SyntaxError",
    "SyntaxWarning",
    "SystemError",
    "SystemExit",
    "TabError",
    "TimeoutError",
    "True",
    "TypeError",
    "UnboundLocalError",
    "UnicodeDecodeError",
    "UnicodeEncodeError",
    "UnicodeError",
    "UnicodeTranslateError",
    "UnicodeWarning",
    "UserWarning",
    "ValueError",
    "Warning",
    "ZeroDivisionError",
    "__IPYTHON__",
    "__build_class__",
    "__debug__",
    "__doc__",
    "__import__",
    "__loader__",
    "__name__",
    "__package__",
    "__spec__",
    "abs",
    "aiter",
    "all",
    "anext",
    "any",
    "ascii",
    "bin",
    "bool",
    "breakpoint",
    "bytearray",
    "bytes",
    "callable",
    "chr",
    "classmethod",
    "compile",
    "complex",
    "copyright",
    "credits",
    "delattr",
    "dict",
    "dir",
    "display",
    "divmod",
    "enumerate",
    "eval",
    "exec",
    "execfile",
    "filter",
    "float",
    "format",
    "frozenset",
    "get_ipython",
    "getattr",
    "globals",
    "hasattr",
    "hash",
    "help",
    "hex",
    "id",
    "input",
    "int",
    "isinstance",
    "issubclass",
    "iter",
    "len",
    "license",
    "list",
    "locals",
    "map",
    "max",
    "memoryview",
    "min",
    "next",
    "object",
    "oct",
    "open",
    "ord",
    "pow",
    "print",
    "property",
    "range",
    "repr",
    "reversed",
    "round",
    "runfile",
    "set",
    "setattr",
    "slice",
    "sorted",
    "staticmethod",
    "str",
    "sum",
    "super",
    "tuple",
    "type",
    "vars",
    "zip",
]

# %% ../nbs/02_helpers.ipynb 5
CACHE_DIR = Path.home() / ".cache" / "code_tokenizers"
CACHE_DIR.mkdir(parents=True, exist_ok=True)

# | export
_GRAMMARs = {
    "python": "https://github.com/tree-sitter/tree-sitter-python/archive/refs/tags/v0.20.0.zip",
}

# %% ../nbs/02_helpers.ipynb 6
def download_grammar(language):
    """
    Download the tree-sitter grammars for the specified languages.

    If the languages argument is the string 'all', all available grammars will be downloaded.
    Otherwise, the argument should be a list of language codes to download.
    """
    try:
        url = _GRAMMARs[language]
    except KeyError as e:
        raise ValueError(
            f"Invalid or unsupported language: {e}. Supported languages: {list(_GRAMMARs.keys())}"
        )

    langs = []
    grammar_dir = CACHE_DIR / "grammars"
    grammar_dir.mkdir(exist_ok=True)
    repo_dir = grammar_dir / language
    if not repo_dir.exists():
        # Download the tagged archive
        urllib.request.urlretrieve(url, f"{repo_dir}.zip")
        # Unzip the repository archive and remove the zip file
        with zipfile.ZipFile(f"{repo_dir}.zip", "r") as zip_ref:
            zip_ref.extractall(grammar_dir)
        os.remove(f"{repo_dir}.zip")
        # move the contents of the tagged archive to the repo directory
        for f in grammar_dir.iterdir():
            if f.is_dir() and f.name.startswith("tree-sitter-"):
                shutil.move(f, repo_dir)

    lang_file = repo_dir / "languages.so"
    if not lang_file.exists():
        Language.build_library(
            # Store the library in the directory
            str(lang_file),
            # Include one or more languages
            [repo_dir],
        )
    return lang_file

# %% ../nbs/02_helpers.ipynb 8
def unroll_node_types(
    nested_node_types: dict,  # node_types from tree-sitter
) -> list:  # list of node types
    """Unroll nested node types into a flat list of node types. This includes subtypes as well."""
    node_types = [node_type["type"] for node_type in nested_node_types]
    node_subtypes = [
        node_subtype["type"]
        for node_type in node_types
        if "subtypes" in node_type
        for node_subtype in node_type["subtypes"]
    ]
    return list(set(node_types + node_subtypes))

# %% ../nbs/02_helpers.ipynb 9
def get_parser(lang):
    lang_file = download_grammar(lang)
    language = Language(
        str(lang_file),
        lang,
    )
    # Grab the node types from the tree-sitter language
    node_path = lang_file.parent / "src" / "node-types.json"
    with open(node_path) as f:
        node_types = json.load(f)
    node_types = unroll_node_types(node_types)
    if lang == "python":
        node_types.append("as_pattern_target")
        node_types.append("ERROR")

    # Create a parser for the language
    parser = Parser()
    parser.set_language(language)
    return parser, node_types

# %% ../nbs/02_helpers.ipynb 11
def get_query(language, program_lang):
    "Get a query based on the language"
    if program_lang == "python":
        return language.query(
            """
            (function_definition
                name: (identifier) @func.name)

            (class_definition
                name: (identifier) @class.name)
            """
        )

# %% ../nbs/02_helpers.ipynb 12
def get_internal_methods(file_contents, tokenizer):
    """
    Get all the internal methods in a set of files
    """
    project_content = "\n\n".join(file_contents)
    tree = tokenizer.parser.parse(project_content.encode())
    root_node = tree.root_node
    query = get_query(tokenizer.language, tokenizer.program_lang)
    captures = query.captures(root_node)
    # make sure to ignore dunders
    internal_methods = {
        node.text.decode()
        for node, _ in captures
        if not node.text.decode().startswith("__")
    }
    return internal_methods

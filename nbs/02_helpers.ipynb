{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helpers\n",
    "\n",
    "> This module contains all the helper functions for this library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e7bba5714d4570aff620f56588ed84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba89881745242318046c1a79684242b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|eval: false\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "ds = load_dataset(\"bigcode/the-stack-smol\", data_dir=\"data/python\", split=\"train\")\n",
    "\n",
    "repo_files = {}\n",
    "for repo_name in tqdm(set(ds[\"repository_name\"]), desc=\"Processing repos\"):\n",
    "    rows_w_repo = ds.filter(lambda example: example[\"repository_name\"] == repo_name)\n",
    "\n",
    "    if len(rows_w_repo) > 1:\n",
    "        repo_files[repo_name] = [row[\"content\"] for row in rows_w_repo]\n",
    "        if len(repo_files) > 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_query(language, program_lang):\n",
    "    \"Get a query based on the language\"\n",
    "    if program_lang == \"python\":\n",
    "        return language.query(\"\"\"\n",
    "            (function_definition\n",
    "                name: (identifier) @func.name)\n",
    "\n",
    "            (class_definition\n",
    "                name: (identifier) @class.name)\n",
    "            \"\"\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_internal_methods(file_contents, tokenizer):\n",
    "    \"\"\"\n",
    "    Get all the internal methods in a set of files\n",
    "    \"\"\"\n",
    "    project_content = \"\\n\\n\".join(file_contents)\n",
    "    tree = tokenizer.parser.parse(project_content.encode())\n",
    "    root_node = tree.root_node\n",
    "    query = get_query(tokenizer.language, tokenizer.program_lang)\n",
    "    captures = query.captures(root_node)\n",
    "    # make sure to ignore dunders\n",
    "    internal_methods = {node.text.decode() for node, _ in captures if not node.text.decode().startswith(\"__\")}\n",
    "    return internal_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'V1ListItemsRequest',\n",
       " 'V1RetrieveBusinessRequest',\n",
       " 'batch_token',\n",
       " 'to_dict',\n",
       " 'to_str'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "from code_tokenizers.core import CodeTokenizer\n",
    "\n",
    "py_tokenizer = CodeTokenizer.from_pretrained(\"gpt2\", \"python\")\n",
    "\n",
    "internal_methods = get_internal_methods(repo_files[\"reduceus/connect-python-sdk\"], py_tokenizer)\n",
    "internal_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('code_tokenizers')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

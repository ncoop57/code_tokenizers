{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cli\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp cli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "import code_tokenizers\n",
    "import os\n",
    "import shutil\n",
    "import urllib.request\n",
    "\n",
    "from fastcore.script import *\n",
    "from pathlib import Path\n",
    "from tree_sitter import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide # fmt: skip\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "_GRAMMARs = {\n",
    "    \"python\": \"https://github.com/tree-sitter/tree-sitter-python/archive/refs/tags/v0.20.0.zip\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def _download_grammars(languages):\n",
    "    \"\"\"\n",
    "    Download the tree-sitter grammars for the specified languages.\n",
    "\n",
    "    If the languages argument is the string 'all', all available grammars will be downloaded.\n",
    "    Otherwise, the argument should be a list of language codes to download.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        grammars = (\n",
    "            _GRAMMARs if languages == \"all\" else {k: _GRAMMARs[k] for k in languages}\n",
    "        )\n",
    "    except KeyError as e:\n",
    "        raise ValueError(\n",
    "            f\"Invalid or unsupported language: {e}. Supported languages: {list(_GRAMMARs.keys())}\"\n",
    "        )\n",
    "\n",
    "    langs = []\n",
    "    grammar_dir = Path(code_tokenizers.__file__).parent / \"grammars\"\n",
    "    grammar_dir.mkdir(exist_ok=True)\n",
    "    for name, url in grammars.items():\n",
    "        repo_dir = grammar_dir / name\n",
    "        if not repo_dir.exists():\n",
    "            # Download the tagged archive\n",
    "            urllib.request.urlretrieve(url, f\"{repo_dir}.zip\")\n",
    "            # Unzip the repository archive and remove the zip file\n",
    "            shutil.unpack_archive(f\"{repo_dir}.zip\", repo_dir)\n",
    "            os.remove(f\"{repo_dir}.zip\")\n",
    "            ts_path = list(repo_dir.iterdir())[0]\n",
    "            # Move the contents of the tagged archive to the repo directory\n",
    "            for f in ts_path.iterdir():\n",
    "                shutil.move(f, repo_dir)\n",
    "\n",
    "        langs.append(str(repo_dir))\n",
    "\n",
    "    Language.build_library(\n",
    "        # Store the library in the directory\n",
    "        str(grammar_dir / \"tree-sitter-languages.so\"),\n",
    "        # Include one or more languages\n",
    "        langs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the above method\n",
    "_download_grammars(\"all\")\n",
    "\n",
    "grammar_dir = Path(code_tokenizers.__file__).parent / \"grammars\"\n",
    "for name, _ in _GRAMMARs.items():\n",
    "    repo_dir = grammar_dir / name\n",
    "    assert repo_dir.exists()\n",
    "\n",
    "assert (grammar_dir / \"tree-sitter-languages.so\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "@call_parse\n",
    "def download_grammars(\n",
    "    languages: Param(\"Languages to download\", str, nargs=\"+\") = \"all\",\n",
    "):\n",
    "    \"\"\"Download Tree-sitter grammars\"\"\"\n",
    "    _download_grammars(languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('code_tokenizers')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
